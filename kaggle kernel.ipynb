{
  "cells": [
    {
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true
      },
      "cell_type": "code",
      "source": "# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom sklearn.preprocessing import LabelEncoder\nfrom collections import defaultdict\nfrom sklearn.model_selection import train_test_split\nfrom imblearn.over_sampling import SMOTE\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import roc_curve, auc\nimport matplotlib.pyplot as plt\nfrom xgboost import XGBRegressor, XGBClassifier\nimport lightgbm as lgb\nfrom sklearn.model_selection import StratifiedKFold, KFold, LeaveOneOut\nfrom sklearn.metrics import mean_squared_error\nfrom keras.layers import Dense, Input\nfrom keras.models import Model\nfrom sklearn.svm import SVR\nfrom sklearn.ensemble import RandomForestClassifier\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "234878273c3eab032d842283c9f7d4decfc94e14"
      },
      "cell_type": "code",
      "source": "# evaluation function\n\ndef eval_auc(y_test, pred):\n    false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, pred)\n    roc_auc = auc(false_positive_rate, true_positive_rate)\n    print(roc_auc)\n    plt.plot(false_positive_rate, true_positive_rate, 'b', label='AUC = %0.2f'% roc_auc)\n    plt.legend(loc='lower right')\n    plt.plot([0,1],[0,1],'r--')\n    plt.xlim([-0.1,1.2])\n    plt.ylim([-0.1,1.2])\n    plt.ylabel('True Positive Rate')\n    plt.xlabel('False Positive Rate')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "248037a6ad556e34fa7ca9b73eebf255a65088a6"
      },
      "cell_type": "markdown",
      "source": "# Read data"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "e3e72b235cab1a1bf82e1032da40e5ddca217a10"
      },
      "cell_type": "code",
      "source": "train_set = pd.read_csv('../input/saftey_efficay_myopiaTrain.csv')\ntest_set = pd.read_csv('../input/saftey_efficay_myopiaTest.csv')\n\nprint('train set shape:', train_set.shape)\nprint('test set shape:', test_set.shape)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "1288eb1123d6f987a834ecd2cf219124dd693dbc"
      },
      "cell_type": "markdown",
      "source": "# Hendle missing values"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "8a2cecd544a10f5e841547e57eab1041800613ac"
      },
      "cell_type": "code",
      "source": "train_set = train_set.dropna(how='all')\n\ntrain_set = train_set.apply(lambda x: x.replace([' ', '', 'NaN', 'nan', 'None'], np.nan))\ntest_set = test_set.apply(lambda x: x.replace([' ', '', 'NaN', 'nan', 'None'], np.nan))\n\n# keeping only the columns that has less then 0.5 missing values - train set\ntrain_set = train_set[train_set.columns[train_set.isnull().mean() < 0.5]]\n\n# split to catagorial and numeric columns from remaining columns\ncatigorial_columns = train_set.select_dtypes(include='object').columns\nnumeric_columns = train_set.columns[~train_set.columns.isin(np.append(catigorial_columns, 'Class'))]\n\n# keeping only the columns that has less then 0.5 missing values - test set\ntest_columns = train_set.columns[~train_set.columns.isin(['Class'])]\ntest_set = test_set[test_columns]",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "0572d7f95ee0739689efa59afd68df0da4e0896e"
      },
      "cell_type": "code",
      "source": "print('train set shape:', train_set.shape)\nprint('test set shape:', test_set.shape)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "707986204b1ee02d0f49330d00f590faee17d479"
      },
      "cell_type": "markdown",
      "source": "# Preprocess"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "bfcccd8e5944a5cc6dcc005a3157da68422f1530"
      },
      "cell_type": "code",
      "source": "# fillna for catigorial values using 'null_value' string\n    \nfor col_name in catigorial_columns:\n    train_set[col_name].fillna('null_value', inplace=True)\n    test_set[col_name].fillna('null_value', inplace=True)\nfor col_name in catigorial_columns:\n    le  = LabelEncoder()\n    le.fit(pd.concat([train_set[col_name], test_set[col_name]]))\n    train_set[col_name] = le.transform(train_set[col_name])\n    test_set[col_name] = le.transform(test_set[col_name])\n    \n# fillna for numeric values using mean values\nfor col_name in numeric_columns:\n    mean_val = train_set[col_name].mean()\n    train_set[col_name].fillna(mean_val, inplace=True)\n    test_set[col_name].fillna(mean_val, inplace=True)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "5ab2c03faa15c83415d26e9bf73fd6e8d0809488"
      },
      "cell_type": "markdown",
      "source": "## Split to feature and target"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "7ba03b73097447d9f5fc92b28c21eae0e960e537"
      },
      "cell_type": "code",
      "source": "x_train_set = train_set.iloc[:, :-1]\ny_train_set = train_set.iloc[:, -1]",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "ca51f2abd15b3b839d2f678fbe0622817b151970"
      },
      "cell_type": "code",
      "source": "print(\"counts of label '1': {}\".format(sum(y_train_set==1)))\nprint(\"counts of label '0': {} \\n\".format(sum(y_train_set==0)))\nprint('imbalance ratio:', sum(y_train_set==0)/sum(y_train_set==1))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "25e51f647d913af3fff0515ec225fbac6d6de571"
      },
      "cell_type": "markdown",
      "source": "\n# Get more '1' lable recoreds using SMOTE "
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "8e526cc0175fdf82c962c995e2569672174ffb81"
      },
      "cell_type": "code",
      "source": "# print(\"Before OverSampling, counts of label '1': {}\".format(sum(y_train_set==1)))\n# print(\"Before OverSampling, counts of label '0': {} \\n\".format(sum(y_train_set==0)))\n\n# sm = SMOTE(random_state=2)\n# x_train_smote, y_train_smote = sm.fit_sample(x_train_set, y_train_set.ravel())\n\n# print('After OverSampling, the shape of train_X: {}'.format(x_train_smote.shape))\n# print('After OverSampling, the shape of train_y: {} \\n'.format(y_train_smote.shape))\n\n# print(\"After OverSampling, counts of label '1': {}\".format(sum(y_train_smote==1)))\n# print(\"After OverSampling, counts of label '0': {}\".format(sum(y_train_smote==0)))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "b1e550f113ff55be65a86a6f137826e569abb8af"
      },
      "cell_type": "markdown",
      "source": "# Building models"
    },
    {
      "metadata": {
        "_uuid": "f9dba2780a1a0eda9f8d98b48c4179dfffa0ba7a"
      },
      "cell_type": "markdown",
      "source": "# lgb model with leave-one-out cross validation"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "0a469ab8d334650eb5910df06d1add2fcf55987b"
      },
      "cell_type": "code",
      "source": "# x = x_train_set.values\n# y = y_train_set.values\n\n# loo = LeaveOneOut()\n# train_predictions_lgb_loo = np.zeros(len(x))\n# predictions_lgb_loo = np.zeros(len(test_set))\n# n_splits_loo = loo.get_n_splits(x)\n\n# lgb_params = {'num_leaves': 200,\n#              'min_data_in_leaf': 149, \n#              'objective':'regression',\n#              'max_depth': 7,\n#              'learning_rate': 0.01,\n#              \"boosting\": \"gbdt\",\n#              \"feature_fraction\": 0.7522,\n#              \"bagging_freq\": 1,\n#              \"bagging_fraction\": 0.7083 ,\n#              \"bagging_seed\": 11,\n#              \"metric\": 'rmse',\n#              \"lambda_l1\": 0.2634,\n#              \"random_state\": 133\n#              }\n\n# for train_index, test_index in loo.split(x):\n#     X_train, X_test = x[train_index], x[test_index]\n#     y_train, y_test = y[train_index], y[test_index]\n    \n#     lgb_loo_train = lgb.Dataset(X_train, y_train)\n#     lgb_loo_eval = lgb.Dataset(X_test, y_test, reference=lgb_loo_train)\n    \n#     lgb_loo_model = lgb.train(lgb_params, lgb_loo_train, num_boost_round=20, valid_sets=lgb_loo_eval, early_stopping_rounds=5)\n    \n#     train_predictions_lgb_loo[test_index] = lgb_loo_model.predict(X_test, num_iteration=lgb_loo_model.best_iteration)\n    \n#     predictions_lgb_loo += lgb_loo_model.predict(test_set, num_iteration=lgb_loo_model.best_iteration) / n_splits_loo\n\n# eval_auc(y, train_predictions_lgb_loo)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "1a40db2d1e8540f8de6824638f3a1bb44fe7d97c"
      },
      "cell_type": "markdown",
      "source": "# XGB regressor and lgb regressor with Stratified-5-fold cross validation"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "c67bac4ac171191f884c7683a2677420ae66a048"
      },
      "cell_type": "code",
      "source": "x = x_train_set.values\ny = y_train_set.values\n\nskf_folds = StratifiedKFold(n_splits=5, shuffle=True, random_state=24)\nn_splits_skf = skf_folds.get_n_splits(x)\n\ntrain_predictions_xgb_skf_reg = np.zeros(len(x))\npredictions_xgb_skf_reg = np.zeros(len(test_set))\n\n# train_predictions_lgb_skf_reg = np.zeros(len(x))\n# predictions_lgb_skf_reg = np.zeros(len(test_set))\n\nnumber_of_fold = 1\nfor train_index, test_index in skf_folds.split(x, y):\n    X_train, X_test = x_train_set.iloc[train_index], x_train_set.iloc[test_index]\n    y_train, y_test = y_train_set.iloc[train_index], y_train_set.iloc[test_index]\n    \n    print('for fold ', number_of_fold, ' count of lable 0 on train set: ', sum(y_train==0))\n    print('for fold ', number_of_fold, ' count of lable 1 on train set: ', sum(y_train==1))\n    number_of_fold = number_of_fold + 1\n    \n    eval_set = [(X_train, y_train), (X_test, y_test)]\n    \n    xgb_model_reg_skf = XGBRegressor(n_estimators=100, learning_rate=0.01, gamma=0, \n                                     subsample=0.8, colsample_bytree=1, max_depth=7)\n    xgb_model_reg_skf.fit(X_train, y_train, eval_set=eval_set, verbose=False)\n    \n#     lgb_model_reg_skf = lgb.sklearn.LGBMRegressor(is_unbalance=True, n_estimators=200, \n#                                               num_leaves=5, learning_rate =0.01, subsample=0.8, \n#                                               colsample_bytree=0.6, max_depth=7)\n#     lgb_model_reg_skf.fit(X_train, y_train, eval_set=eval_set, verbose=False)\n    \n    train_predictions_xgb_skf_reg[test_index] = xgb_model_reg_skf.predict(X_test)\n    predictions_xgb_skf_reg += (xgb_model_reg_skf.predict(test_set) / (n_splits_skf + 1))\n    \n#     train_predictions_lgb_skf_reg[test_index] = lgb_model_reg_skf.predict(X_test)\n#     predictions_lgb_skf_reg += (lgb_model_reg_skf.predict(test_set) / (n_splits_skf + 1))\n    \n#     total_pred = (train_predictions_xgb_skf_reg[test_index] + train_predictions_lgb_skf_reg[test_index]) / 2\n#     eval_auc(y_test, total_pred)\n    eval_auc(y_test, train_predictions_xgb_skf_reg[test_index])\n\n# total_pred = (train_predictions_xgb_skf_reg + train_predictions_lgb_skf_reg) / 2\n# eval_auc(y_train_set, total_pred)\neval_auc(y_train_set, train_predictions_xgb_skf_reg)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "12959da72b099c94fe73ca2d9f566ee2f6b4d98a"
      },
      "cell_type": "code",
      "source": "# add the prediction on the test set of the XGBRegressor model after training on ALL the data\n\nxgb_model_reg = XGBRegressor(n_estimators=100, learning_rate=0.01, gamma=0, \n                             subsample=0.8, colsample_bytree=1, max_depth=7)\nxgb_model_reg.fit(x_train_set, y_train_set, verbose=False)\npredictions_xgb_skf_reg += (xgb_model_reg.predict(test_set) / (n_splits_skf + 1))\n\n# lgb_model_reg = lgb.sklearn.LGBMRegressor(is_unbalance=True, n_estimators=200, \n#                                           num_leaves=5, learning_rate =0.01, subsample=0.8, \n#                                           colsample_bytree=0.6, max_depth=7)\n# lgb_model_reg.fit(x_train_set, y_train_set, verbose=False)\n# predictions_lgb_skf_reg += (lgb_model_reg.predict(test_set) / (n_splits_skf + 1))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "2fe16a615edb3af336f2ec193cab07e414d68512"
      },
      "cell_type": "markdown",
      "source": "# XGB regressor "
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "3c8eeadf525174d02a1e87ffd7932cedc49c1faf"
      },
      "cell_type": "code",
      "source": "# xgb_model_reg = XGBRegressor(n_estimators=100, learning_rate=0.01, gamma=0, subsample=0.8, colsample_bytree=1, max_depth=7, nthread=1)\n# xgb_model_reg.fit(x_train_set, y_train_set)\n# xgb_reg_pred = xgb_model_reg.predict(test_set)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "a9bdda350acd68968c3ddee798c10fe8248c1469"
      },
      "cell_type": "markdown",
      "source": "# using all models as ensambel and calculate the average prediction for test set"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "f00f2464a6a1ca41bc538789051fe6d044ddd7a9"
      },
      "cell_type": "code",
      "source": "# total_test_pred = (predictions_xgb_skf_reg + predictions_lgb_skf_reg) / 2",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "18f9ae284ebe75bda524b0de9f22115367ec1ebe"
      },
      "cell_type": "markdown",
      "source": "# Writing results to sample submmitions file"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "103e40d4a09c3e80d7995d44ba33c359e1ea845e"
      },
      "cell_type": "code",
      "source": "sample_submmision = pd.DataFrame()\nsample_submmision['Id'] = test_set.index + 1\nsample_submmision['Class'] = predictions_xgb_skf_reg #total_test_pred\nsample_submmision.sort_values(by=['Id'], inplace=True)\nsample_submmision.to_csv('sample_submmision.csv', index=False)",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}